import json
from rdkit import Chem
from rdkit.Chem import AllChem
import subprocess
from tempfile import NamedTemporaryFile, TemporaryDirectory
import re
import os
import glob
from math import e
import random
import numpy as np
from copy import deepcopy

from chems_thermo import ChemsThermo

KCAL_PER_HARTREE = 627.5094740631


class ChemsThermoXtb(ChemsThermo):
    def __init__(self, data_dir):
        super().__init__(data_dir)

        self.chems_thermo_xtb_fn = os.path.join(self.thermo_dir, 'chems_thermo_xtb.jsonl')
        self.reactions_thermo_xtb_fn = os.path.join(self.thermo_dir, 'reactions_thermo_xtb.jsonl')

        self._file_sorting_prefs[self.chems_thermo_xtb_fn] = 'cid'
        self._file_sorting_prefs[self.reactions_thermo_xtb_fn] = 'rid'
    

    def get_structures(self, input_sdf, out_fn):
        entries = []
        with open(input_sdf) as f:
            text = f.read().strip('\n$')
        entries = text.split('$$$$')

        with open(out_fn, 'w') as f:
            for entry in entries:
                entry = entry.strip()
                entry_lines = entry.split('\n')
                cid = int(entry_lines[0])
                content = '\n'.join(entry_lines)
                f.write(json.dumps({'cid': cid, 'sdf': content}) + '\n')



    def __generate_conformers(self, mol, num_confs=20):
        mol = Chem.AddHs(mol)
        
        AllChem.EmbedMultipleConfs(mol, numConfs=num_confs, pruneRmsThresh=0.1)
        
        for conf in mol.GetConformers():
            AllChem.UFFOptimizeMolecule(mol, confId=conf.GetId())
        
        return mol


    def __conf_to_xyz(self, mol, conf=None):
        if not conf:
            conf = mol.GetConformer()

        xyz_str = f"{mol.GetNumAtoms()}\nGenerated by RDKit\n"
        for atom in mol.GetAtoms():
            pos = conf.GetAtomPosition(atom.GetIdx())
            xyz_str += f"{atom.GetSymbol()} {pos.x:.6f} {pos.y:.6f} {pos.z:.6f}\n"
        return xyz_str

    def __get_conformers_xyz(self, mol):
        confs_xyz = []
        for conf in mol.GetConformers():
            xyz_str = self.__conf_to_xyz(mol, conf)
            confs_xyz.append(xyz_str)
        
        return confs_xyz


    def convert_to_xyz_rdkit(self, input_file, output_dir):
        with open(input_file) as f:
            entries = [json.loads(x) for x in f.read().strip().split('\n')]

        if not os.path.exists(output_dir):
            os.mkdir(output_dir)
        
        for i, entry in enumerate(entries):
            cid = entry['cid']
            out_file_path = os.path.join(output_dir, f"{cid}.json")
            if os.path.exists(out_file_path):
                continue
            try:
                sdf_text = entry['sdf'].replace("\\n", "\n")
                mol = Chem.MolFromMolBlock(sdf_text, removeHs=False)
                if mol is None:
                    print(f"Failed to read SDF for CID {entry['cid']}")
                    continue
                
                # Ensure 3D coordinates
                if mol.GetNumConformers() == 0:
                    AllChem.EmbedMolecule(mol)

                mol = self.__generate_conformers(mol)
                confs_xyz = self.__get_conformers_xyz(mol)
                
                with open(out_file_path, 'w') as f:
                    f.write(json.dumps(confs_xyz, indent=2) + '\n')

                print(f"({i+1}/{len(entries)}) Generated {len(confs_xyz)} conformers for {entry['cid']}")
            except Exception as e:
                print(f"Failed CID {entry['cid']}: {e}")




    def __optimize_structure_crest(self, crest_cmd, file_xyz, work_dir, chem, result_path):
        mol = Chem.MolFromSmiles(chem['smiles'])
        if not mol:
            return False

        mol = Chem.AddHs(mol)

        if mol.GetNumConformers() == 0:
            AllChem.EmbedMolecule(mol)

        AllChem.EmbedMolecule(mol, randomSeed=42)
        if AllChem.MMFFHasAllMoleculeParams(mol):
            AllChem.MMFFOptimizeMolecule(mol)
        else:
            AllChem.UFFOptimizeMolecule(mol)
        
        mol_xyz = self.__conf_to_xyz(mol)

        file_xyz.write(mol_xyz.encode())
        file_xyz.flush()

        def __run_crest_opt(crest_cmd, filename_xyz, work_dir, timeout):
            proc = subprocess.Popen([crest_cmd, filename_xyz, '--opt'], cwd=work_dir, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            try:
                # For some reason crest stalls in some cases
                proc.wait(timeout=timeout)
            except subprocess.TimeoutExpired:
                proc.kill()
                proc.wait()

            return proc

        init_tries_num = 2
        timeout = 10
        for try_i in range(init_tries_num):
            proc = __run_crest_opt(crest_cmd, file_xyz.name, work_dir, timeout)
            if proc.returncode == 0 and os.path.exists(result_path):
                return True
        
        def get_perturbed_mol(mol):
            perturbed_mol = deepcopy(mol)
            noise_std = 0.25
            conf = perturbed_mol.GetConformer()
            for i in range(mol.GetNumAtoms()):
                pos = np.array(conf.GetAtomPosition(i))
                perturbation = np.random.normal(0, noise_std, size=3)
                new_pos = pos + perturbation
                conf.SetAtomPosition(i, new_pos)
            
            return perturbed_mol
        
        perturb_tries_num = 5
        for try_i in range(perturb_tries_num):
            perturbed_mol = get_perturbed_mol(mol)
            xyz_str = self.__conf_to_xyz(perturbed_mol)
            file_xyz.seek(0)
            file_xyz.truncate()
            file_xyz.write(xyz_str.encode())
            file_xyz.flush()

            proc = __run_crest_opt(crest_cmd, file_xyz.name, work_dir, timeout)
            if proc.returncode == 0 and os.path.exists(result_path):
                return True

        return False
        

        


    def generate_missing_structures(self, conformers_dir, chems_jsonl, crest_cmd='crest', obabel_cmd='obabel'):
        with open(chems_jsonl) as f:
            chems = [json.loads(x) for x in f.read().strip().split('\n')]

        processed_files = set(os.listdir(conformers_dir))
        chems = list(filter(lambda x: f"{x['cid']}.json" not in processed_files, chems))
        print(f"Submitted {len(chems)} compounds with missing structures")

        for chem in chems:
            cid = chem['cid']
            name = chem['cmpdname']

            try:
                print(f"\nProcessing {cid} ('{name}')")
                with NamedTemporaryFile(suffix='.xyz', delete=True) as tmp, TemporaryDirectory(suffix='_tmp') as work_dir:
                    result_path = os.path.join(work_dir, 'crestopt.xyz')
                    status = self.__optimize_structure_crest(crest_cmd, tmp, work_dir, chem, result_path)
                    if not status:
                        print(f"Failed to optimize structure for {cid} ('{name}')")
                        continue
                    
                    result_sdf_path = os.path.join(work_dir, 'mol.sdf')
                    proc = subprocess.Popen([obabel_cmd, result_path, '-O', result_sdf_path, '--gen3d'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd=work_dir)
                    proc.wait()
                    if proc.returncode != 0 or not os.path.exists(result_sdf_path):
                        print(f"obabel failed to convert optimized geometry to sdf for {cid} ('{name}')")
                        continue

                    mol_opt = Chem.SDMolSupplier(result_sdf_path)[0]

                print(f"Found optimal structure for {cid} ('{name}'). Generating conformers")
                mol_opt = self.__generate_conformers(mol_opt)
                confs_xyz = self.__get_conformers_xyz(mol_opt)
                if(len(confs_xyz) == 0):
                    raise Exception("len(confs_xyz) == 0")

                out_fn = os.path.join(conformers_dir, f"{cid}.json")
                with open(out_fn, 'w') as f:
                    f.write(json.dumps(confs_xyz, indent=2) + '\n')
                
                print(f"Generated {len(confs_xyz)} for {cid} ('{name}')")


            except Exception as e:
                print(f"Failed to generate conformers for {cid} ('{name}'): {e}")

            



    def __compute_boltzmann_average(self, results):
        results_num = len(results)
        Gt_min = min([x['Gt'] for x in results])
        factor = 0.000944185024051871   # # k*T / <1 hartree>
        coeffs = [e**(-(x['Gt']-Gt_min)/factor) for x in results]

        Ht_av = sum([coeffs[i]*results[i]['Ht'] for i in range(results_num)])/sum(coeffs)
        Gt_av = sum([coeffs[i]*results[i]['Gt'] for i in range(results_num)])/sum(coeffs)

        return Ht_av, Gt_av


    def __clear_dir(self, dir_name):
        files = glob.glob(os.path.join(dir_name, "*"))

        for f in files:
            if os.path.isfile(f):
                os.remove(f)

    def __run_xtb_single(self, conformers_xyz, max_conformers=5, xtb_cmd='xtb', method='gfn2'):
        results = []
        with TemporaryDirectory(suffix='_tmp') as work_dir:
            random.shuffle(conformers_xyz)
            conf_i = 0
            while len(results) < max_conformers and conf_i < len(conformers_xyz):
                try:
                    conf = conformers_xyz[conf_i]
                    with NamedTemporaryFile(suffix='.xyz') as tmp:
                        tmp.write(conf.encode())
                        tmp.flush()

                        proc = subprocess.Popen([xtb_cmd, tmp.name, '--ohess', '--strict', f'--method={method}'], cwd=work_dir, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                        result, stderr = proc.communicate()
                        if proc.returncode != 0:
                            raise Exception('xtb energy failed')

                        self.__clear_dir(work_dir)

                    def convert_exponential(value):
                        mantiss, power = value.split('E')
                        mantiss = float(mantiss)
                        power = int(power)

                        return mantiss * 10**power
                        
                    
                    energy_match = re.findall(r'(?<=TOTAL ENERGY).+?(?= Eh)', result)
                    if not energy_match:
                        raise Exception(f"not found energy")

                    energy = float(energy_match[0].strip())

                    Ht_match = re.findall(r'(?<=TOTAL ENTHALPY).+?(?=Eh)', result)
                    if not Ht_match:
                        raise Exception(f"not found Ht")

                    Ht = float(Ht_match[0].strip())

                    Gt_match = re.findall(r'(?<=TOTAL FREE ENERGY).+?(?=Eh)', result)
                    if not Gt_match:
                        raise Exception(f"not found Gt")

                    Gt = float(Gt_match[0].strip())
                    
                    results.append({'Ht': Ht, 'Gt': Gt, 'E': energy})
                except Exception as e:
                    pass

                conf_i += 1
        
        if not results:
            return None
        
        Ht, Gt = self.__compute_boltzmann_average(results)
        
        return len(results), Ht, Gt


    def run_xtb(self, conformers_dir, output_file, order_file=None, xtb_cmd='xtb'):
        os.environ['MKL_NUM_THREADS'] = "3"
        os.environ['OMP_NUM_THREADS'] = "3,1"
        os.environ['OMP_STACKSIZE'] = "4G"

        if os.path.exists(output_file):
            with open(output_file) as f:
                processed_cids = set([json.loads(x)['cid'] for x in f.read().strip().split('\n')])
        else:
            processed_cids = set()
        
        if order_file:
            with open(order_file) as f:
                order = [f"{x}.json" for x in json.loads(f.read())]

        max_conformers = 1

        with open(output_file, 'a') as f_out:
            filenames = os.listdir(conformers_dir)
            for fn in order if order_file else filenames:
                cid = int(fn.split('.')[0])
                if cid in processed_cids:
                    print(f"Skipping {cid}...")
                    continue
                fn_path = os.path.join(conformers_dir, fn)
                if not os.path.exists(fn_path):
                    print(f"Not found {cid}. Skipping...")
                    continue
                with open(os.path.join(conformers_dir, fn)) as f_conf:
                    conforms_xyz = json.loads(f_conf.read())

                print(f"Submitting {cid} with {len(conforms_xyz)} conformers")
                res = self.__run_xtb_single(conforms_xyz, max_conformers=max_conformers, xtb_cmd=xtb_cmd)
                if res:
                    processed_conf_num, Ht, Gt = res
                    f_out.write(json.dumps({'cid': cid, 'Ht_Eh': Ht, 'Gt_Eh': Gt}) + '\n')
                    f_out.flush()
                    curr_max_conformers = min(max_conformers, len(conforms_xyz))
                    print(f"Processed {cid} ({processed_conf_num}/{curr_max_conformers}). Ht: {Ht} Eh; Gt: {Gt} Eh")
                else:
                    f_out.write(json.dumps({'cid': cid, 'Ht_Eh': None, 'Gt_Eh': None}) + '\n')
                    f_out.flush()
                    print(f"Failed to compute enthalpy for {cid}")
                    


    def delete_cids(self):
        with open('3d_structures.jsonl') as f:
            cids_to_keep = set([f"{json.loads(x)['cid']}.json" for x in f.read().strip().split('\n')])
        
        filenames = os.listdir('conformers/')
        fns_to_remove = list(filter(lambda x: x not in cids_to_keep, filenames))
        print(f"Submitted {len(fns_to_remove)} for deletion")
        for fn in fns_to_remove:
            path = os.path.join('conformers/', fn)
            os.remove(path)
        print("Done")


    def clear_null_enthalpy_entries(self, filename):
        with open(filename) as f:
            entries = [json.loads(x) for x in f.read().strip().split('\n')]
        
        with open(filename, 'w') as f:
            for entry in entries:
                if entry['Ht_Eh'] is not None:
                    f.write(json.dumps(entry) + '\n')


    def compute_formation_values(self, xtb_thermo_fn, out_fn):
        with open('data/chems/chems.jsonl') as f:
            chems = [json.loads(x) for x in f.read().strip().split('\n')]
        
        with open('data/chems/elements.jsonl') as f:
            elements = [json.loads(x) for x in f.read().strip().split('\n')]

        with open(xtb_thermo_fn) as f:
            xtb_thermo_entries = [json.loads(x) for x in f.read().strip().split('\n')]
        
        symb_to_el = {el['symbol']: el for el in elements}
        cid_to_chem = {chem['cid']: chem for chem in chems}
        cid_to_thermo = {th['cid']: th for th in xtb_thermo_entries}
        
        with open(out_fn, 'w') as f_out:
            for entry in xtb_thermo_entries:
                if entry['Ht_Eh'] is None:
                    continue

                cid = entry['cid']
                chem = cid_to_chem[cid]
                name = chem['cmpdname']
                mol = Chem.MolFromInchi(chem['inchi'])
                mol = Chem.AddHs(mol)
                if not mol:
                    print(f"Failed to obtain mol object for '{name}' ({cid})")
                    continue
                
                atom_counts = {}
                for atom in mol.GetAtoms():
                    symbol = atom.GetSymbol()
                    atom_counts[symbol] = atom_counts.get(symbol, 0) + 1
                
                dHf = Ht = entry['Ht_Eh'] * KCAL_PER_HARTREE
                dGf = Gt = entry['Gt_Eh'] * KCAL_PER_HARTREE
                for symbol, count in atom_counts.items():
                    el_entry = symb_to_el[symbol]
                    el_cid = el_entry['cid']
                    el_atom_count = el_entry['atom_count']
                    el_thermo = cid_to_thermo.get(el_cid, {'Ht_Eh': None})

                    if el_thermo['Ht_Eh'] is None:
                        break
                    
                    el_ht = el_thermo['Ht_Eh'] * KCAL_PER_HARTREE / el_atom_count
                    el_gt = el_thermo['Gt_Eh'] * KCAL_PER_HARTREE / el_atom_count
                    
                    dHf -= count * el_ht
                    dGf -= count * el_gt

                else:      
                    out_entry = {'cid': cid, 'Ht': Ht, 'Gt': Gt, 'dHf': dHf, 'dGf': dGf, 'T': 298.15}
                    f_out.write(json.dumps(out_entry) + '\n')


    def print_thermo(self, thermo_fn, n=100):
        with open(thermo_fn) as f:
            thermo = [json.loads(x) for x in f.read().strip().split('\n')]

        with open('data/chems/chems.jsonl') as f:
            chems = [json.loads(x) for x in f.read().strip().split('\n')]
        
        cid_to_chem = {chem['cid']: chem for chem in chems}
        
        for entry in thermo[:n]:
            name = cid_to_chem[entry['cid']]['cmpdname']
            dHf = entry['dHf']
            dGf = entry['dGf']
            print(f"{name}: dHf={dHf}; dGf={dGf}")
    

    def compute_reactions_thermo_xtb(self):
        reactions = self._load_jsonl(self.reactions_parsed_fn)
        thermo = self._load_jsonl(self.chems_thermo_xtb_fn)
        cid_to_thermo = {th['cid']: th for th in thermo}

        KCAL_PER_HARTREE = 627.5094740631

        with open(self.reactions_thermo_xtb_fn, 'w') as f:
            for react in reactions:
                if not react['balanced']:
                    continue
                
                def compute_value(value):
                    def compute_side(side, value):
                        res = 0
                        for entry in react[side]:
                            cid = entry['cid']
                            if cid not in cid_to_thermo or cid_to_thermo[cid][value] is None:
                                return None

                            res += entry['coeff'] * cid_to_thermo[entry['cid']][value]
                        
                        return res

                    v_r = compute_side('reagents', value)
                    v_p = compute_side('products', value)

                    return None if v_r is None or v_p is None else (v_p - v_r) * KCAL_PER_HARTREE
                    
                react_str = self._get_reaction_as_str(react)

                dH = compute_value('Ht_Eh')
                dG = compute_value('Gt_Eh')
                if dH is None and dG is None:
                    continue
                
                f.write(json.dumps({'rid': react['rid'], 'react_str': react_str, 'dH': dH, 'dG': dG}) + '\n')
        



if __name__ == "__main__":
    thermo = ChemsThermoXtb('data/')
    thermo.compute_reactions_thermo_xtb()

    #get_structures('3d.sdf', '3d_structures.jsonl')
    #convert_to_xyz_rdkit('3d_structures.jsonl', 'conformers/')
    #generate_missing_structures('conformers', 'data/chems/chems.jsonl', crest_cmd='/home/me/Downloads/crest/crest')
    #run_xtb('conformers/', 'data/thermo/chems_thermo_xtb_test.jsonl', order_file='data/misc/commonness_sorted_cids.json', xtb_cmd='/home/me/Downloads/xtb-dist/bin/xtb')
    #delete_cids()
    #clear_null_enthalpy_entries('chems_thermo_xtb.jsonl')
    #compute_formation_values('data/thermo/chems_thermo_xtb.jsonl', 'data/thermo/chems_thermo.jsonl')
    #print_thermo('data/thermo/chems_thermo.jsonl', n=1000)